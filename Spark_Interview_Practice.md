# Spark Interview Questions


## Common Questions
Note: Some are specific to Spark/Scala and some are specific to PySpark

	What is PySpark?
	What is a transformation on an RDD? An action? Give examples.
	How do you see the lineage of an RDD?
	What is a broadcast variable? Accumulator?
	What are the API's used in Spark?
	What is coalesce? What is the use of it?
	reduceByKey vs groupByKey. What are they used for?
	Write code to create a Dataframe. How would you put data from a CSV in it?
	Besides SELECT statements, what other spark.sql statements have you used?
	How to do joins when the table name and column names are variables?
	RDD vs DF vs DS? Why to use each one?
	Client vs Cluster mode?
	Spark-submit options?
	What is the SparkSession?
	What is repartitioning? Coalesce? Difference between the two? Which is faster?
	Partitioning  vs Bucketing? How are the files stored?
	Benefits of Spark over Hadoop? Hadoop over Spark?
	What are the different persistence storage levels?
	What is spark?
	What is the Spark Driver?
	What is the Spark Executor?
	Why would you use Spark in a project instead of Hive?
	What file types have you used? Are you familiar with CSV, Parquet, JSON?
	Basic components of Spark?
	How do you create a custom schema for a Dataframe?
	How do you convert an RDD to a Dataframe
	What is a UDF? (User Defined Function) How do you create one?
	How do you print the schema of a Dataframe?
	What is a DAG?
	How do you JOIN two dataframes?
	How do you submit a spark application? What parameters are needed?
	How do you check if a column already exists in a Dataframe?
	How do you add a column to a Dataframe?
	How do you change the name of a column in a dataframe?
